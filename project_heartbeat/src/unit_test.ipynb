{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Algorithm\n",
    "\n",
    "## Instructions\n",
    "1. From the **Pulse Rate Algorithm** Notebook you can do one of the following:\n",
    "   - Copy over all the **Code** section to the following Code block.\n",
    "   - Download as a Python (`.py`) and copy the code to the following Code block.\n",
    "2. In the bottom right, click the <span style=\"color:blue\">Test Run</span> button. \n",
    "\n",
    "### Didn't Pass\n",
    "If your code didn't pass the test, go back to the previous Concept or to your local setup and continue iterating on your algorithm and try to bring your training error down before testing again.\n",
    "\n",
    "### Pass\n",
    "If your code passes the test, complete the following! You **must** include a screenshot of your code and the Test being **Passed**. Here is what the starter filler code looks like when the test is run and should be similar. A passed test will include in the notebook a green outline plus a box with **Test passed:** and in the Results bar at the bottom the progress bar will be at 100% plus a checkmark with **All cells passed**.\n",
    "![Example](example.png)\n",
    "\n",
    "1. Take a screenshot of your code passing the test, make sure it is in the format `.png`. If not a `.png` image, you will have to edit the Markdown render the image after Step 3. Here is an example of what the `passed.png` would look like \n",
    "2. Upload the screenshot to the same folder or directory as this jupyter notebook.\n",
    "3. Rename the screenshot to `passed.png` and it should show up below.\n",
    "![Passed](passed.png)\n",
    "4. Download this jupyter notebook as a `.pdf` file. \n",
    "5. Continue to Part 2 of the Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "nrtnppao4pm",
    "udacity_user_query": ""
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import filtfilt\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ecg, ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[:]\n",
    "def LoadTroikaDataReferenceFile(ref_fl):\n",
    "    \"\"\"\n",
    "    Loads reference data.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        bpm_refs = LoadTroikaDataReferenceFile(ref_fls[0])\n",
    "\n",
    "    Args:\n",
    "        ref_fl: (str) filepath to a troika reference .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ref_bpms .\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(ref_fl)['BPM0']\n",
    "    ret = list(data[:,0])\n",
    "    return ret\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    ret = np.mean(np.abs(best_estimates))\n",
    "    return ret\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "    \"\"\"\n",
    "    Pass band filter function\n",
    "    \"\"\"\n",
    "def filter_band(signal,fs,pass_band=None):\n",
    "    if pass_band:\n",
    "        #nyquist = 0.5 * fs\n",
    "        #normalized_pass_band = (pass_band[0] / nyquist, pass_band[1] / nyquist)\n",
    "        #b, a  = sp.signal.butter(3, normalized_pass_band, btype='bandpass', fs=fs)\n",
    "        b, a  = butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "        return filtfilt(b, a, signal)\n",
    "    else:\n",
    "        return signal\n",
    "    \n",
    "def hampel_filter(y, window_size=3, threshold=3):\n",
    "    \"\"\"\n",
    "    Apply the Hampel filter to smooth out extreme values in the signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - y: The input signal.\n",
    "    - window_size: The size of the window for the median filter.\n",
    "    - threshold: The threshold for identifying outliers.\n",
    "    \n",
    "    Returns:\n",
    "    - Smoothed signal.\n",
    "    \"\"\"\n",
    "    # Apply median filter to obtain the median absolute deviation (MAD)\n",
    "    mad = medfilt(np.abs(y - np.median(y)), kernel_size=window_size)\n",
    "    \n",
    "    # Identify outliers based on the threshold\n",
    "    outliers = np.where(mad > threshold * np.std(y))\n",
    "    \n",
    "    # Replace outliers with the median value\n",
    "    y_filtered = np.copy(y)\n",
    "    y_filtered[outliers] = np.median(y)\n",
    "    \n",
    "    return y_filtered    \n",
    "    \n",
    "def compute_acceleration_resultant(accx, accy, accz):\n",
    "    \"\"\"\n",
    "    Compute the resultant of the acceleration\n",
    "    \"\"\"    \n",
    "    \n",
    "    resultant_acceleration = np.sqrt(accx**2 + accy**2 + accz**2)\n",
    "    return resultant_acceleration    \n",
    "def extract_motion_from_accelerometer(acc,fs,window,step):\n",
    "    \"\"\"\n",
    "    Extract motion using spectrogram\n",
    "    \"\"\"\n",
    "    spec,freqs, _, _ = plt.specgram(acc,NFFT=window*fs,Fs=fs,noverlap=step*fs)\n",
    "    rates = freqs[np.argmax(spec,axis=0)]\n",
    "    return rates \n",
    "def extract_signal_segments(signal,fs,window,step):\n",
    "    \"\"\"\n",
    "    Extract segement of temoral windows of size window each step.\n",
    "    \n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    signal_length = len(signal)\n",
    "    #convertion -> index\n",
    "    window = window * fs\n",
    "    step = step*fs\n",
    "    \n",
    "    i=0\n",
    "    idx_s=0\n",
    "    idx_e=0\n",
    "    while idx_e < signal_length:\n",
    "        idx_s = i * step\n",
    "        idx_e = idx_s +  window\n",
    "        if(idx_e>=signal_length):            \n",
    "            idx_e= signal_length\n",
    "        segment = signal[idx_s:idx_e]\n",
    "        segments.append(segment)\n",
    "        i += 1\n",
    "    return(segments)\n",
    "def extract_frequencies_for_highest_amplitudes(signal,fs,window,step,pass_band=None,n=2,display= False):\n",
    "    \"\"\"\n",
    "    Extracts n frequencies corresponding to n highest amplitude of Fourier Transform of the signal.\n",
    "\n",
    "    Args:\n",
    "        signal: signal\n",
    "        fs: sampling frequency\n",
    "        window: window of the within the signal\n",
    "        step: window's overlaping\n",
    "        pass_band: pass band frequencies interval\n",
    "\n",
    "    Returns:\n",
    "        return the n frequencies and assciate SNR ratio\n",
    "   \"\"\"       \n",
    "    #filter signal by pas_band\n",
    "    signal = filter_band(signal,fs,pass_band=pass_band)\n",
    "    frequencies = []\n",
    "    snrs = [] \n",
    "    segments = extract_signal_segments(signal,fs,window,step);\n",
    "    for segment in segments:\n",
    "        segment_pulsations= extract_ntop_freq(segment,fs,n=n)\n",
    "        segment_snrs = []        \n",
    "        for pulsation in segment_pulsations:\n",
    "            snr = compute_SNR(segment, fs, pulsation ,6/60,display=False)\n",
    "            segment_snrs.append(snr)\n",
    "        frequencies.append(zip(segment_pulsations,segment_snrs))\n",
    "    return frequencies\n",
    "    \n",
    "def extract_ntop_freq(sig, fs,n=3,display= False):\n",
    "    \"\"\"\n",
    "    Extract the first n frequence corresponding to the highest magniture     \n",
    "    \n",
    "    Args:\n",
    "        sig: the signal. \n",
    "        fs: sampling frequency\n",
    "        n: the number of wanted frequencies \n",
    "        display: for debug or understandin\n",
    "    Returns:\n",
    "        The SNR coeficient\n",
    "    \"\"\"     \n",
    "    mag = np.abs(np.fft.rfft(sig))\n",
    "    frq = np.fft.rfftfreq(len(sig),1/fs) \n",
    "\n",
    "    # Assuming mag and frq are your Fourier Transform magnitude and frequency arrays\n",
    "    # Find the indices of the top three max amplitudes\n",
    "    top_indices = np.argsort(mag)[-n:][::-1]\n",
    "\n",
    "    # Extract the corresponding frequencies\n",
    "    top_frequencies = frq[top_indices]\n",
    "    return top_frequencies\n",
    "def compute_SNR(sig, fs, fr_p ,fr_w,display=False):\n",
    "    \"\"\"\n",
    "    Compute the SNR of the signal around frequence fr_p with the window fr_w\n",
    "    Args:\n",
    "        sig: the signal. \n",
    "        fs: sampling frequency\n",
    "        fr_p: frequence \n",
    "        fr_w: frequence window\n",
    "        display: for debug or understandin\n",
    "\n",
    "    Returns:\n",
    "        The SNR coeficient\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute signal power and noise power\n",
    "    signal_power = None\n",
    "    noise_power = None\n",
    "\n",
    "    mag = np.abs(np.fft.rfft(sig))\n",
    "    frq = np.fft.rfftfreq(len(sig),1/fs)\n",
    "\n",
    "    #1st harmonique\n",
    "    fr_h = fr_p * 2\n",
    "\n",
    "    f_w_p = (frq > (fr_p -fr_w))  & (frq < (fr_p + fr_w))\n",
    "    f_w_h = (frq > (fr_h-fr_w))  & (frq < (fr_h + fr_w))\n",
    "\n",
    "    f_w_no = ~ (f_w_p | f_w_h)\n",
    "\n",
    "    if display:\n",
    "        plt.clf()\n",
    "        plt.plot(frq,mag)    \n",
    "        plt.show()\n",
    "\n",
    "    signal_power  = np.sum(mag[f_w_p | f_w_h])\n",
    "    noise_power = np.sum(mag[f_w_no])\n",
    "    # Compute SNR\n",
    "    snr = signal_power / noise_power\n",
    "    snr = 10 * math.log10 (100*snr)\n",
    "    return snr\n",
    "\n",
    "\n",
    "def select_most_common_with_max_coefficient(values, coefficients):\n",
    "    \"\"\"\n",
    "     This code first counts the occurrences of each value and then selects the most common one. In case of ties, \n",
    "     it compares the corresponding coefficients to choose the one with the maximum coefficient and return it with the  \n",
    "     percentage and the maximum coefficient associated with that value.\n",
    "     Args:\n",
    "         List of values  \n",
    "         List of coefficients  \n",
    "     Returns:\n",
    "         most common values with maximum coefficient\n",
    "         percentage of  this value within the whole set\n",
    "         maximum coefficient\n",
    "    \n",
    "    \"\"\"\n",
    "    # Combine values and coefficients into tuples for easier processing\n",
    "    combined_data = list(zip(values, coefficients))\n",
    "\n",
    "    # Count occurrences of each value\n",
    "    value_counts = Counter(values)\n",
    "\n",
    "    # Find the most common values\n",
    "    most_common_values = [item[0] for item in value_counts.most_common()]\n",
    "\n",
    "    # If there are multiple most common values, select the one with the maximum coefficient\n",
    "    selected_value = max(most_common_values, key=lambda val: next(item[1] for item in combined_data if item[0] == val))\n",
    "\n",
    "    # Calculate the percentage of the selected value compared to all values\n",
    "    total_values = len(values)\n",
    "    percentage = (value_counts[selected_value] / total_values)\n",
    "\n",
    "    # Find the maximum coefficient associated with the selected value\n",
    "    max_coefficient = max(item[1] for item in combined_data if item[0] == selected_value)\n",
    "\n",
    "    return selected_value,percentage, max_coefficient\n",
    "\n",
    "\n",
    "def evaluate_bpm(ppg_sources,acc_source,snr_threshold = 15):\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate the heartbeat in beat by minutes, based on multiple ppg signal sources and an accelerometer resultant signal.\n",
    "    Note: The confidence isn't an accurate metrics but we have tried to gives some result based on:\n",
    "          - there is a high probability tha the measure is accurate when multiple ppg captors gives the same result.\n",
    "          - the snr ration is considered faire above the  snr_thresold (default value is 15 DB) and low bellow that thresold\n",
    "    Args:\n",
    "        ppg_sources: frequncies for highest amplitude of the FFT and coresponding SNR for multiple PPG signals.\n",
    "        ppg_sources: frequncies for highest amplitude of the FFT and coresponding SNR for accelerometer signal.\n",
    "        snr_threshold: thershold. fair signal quality above 15 and loq bellow \n",
    "\n",
    "    Returns:\n",
    "        The heartbeat in BPM and a confidence percentage \n",
    "    \"\"\"\n",
    "    \n",
    "    #lookup for first frequency which isn't 0 \n",
    "    move_frequence = None \n",
    "    for pulse_acc,_ in  acc_source:\n",
    "        if pulse_acc != 0:\n",
    "            move_frequence = pulse_acc\n",
    "            break\n",
    "            \n",
    "    eval_bpm = 0\n",
    "    confidence = 0\n",
    "    freqs = []\n",
    "    snrs = []\n",
    "    if isinstance(ppg_sources, list):\n",
    "        for ppg_source in ppg_sources:\n",
    "            for pulse_ppg,snr_ppg in ppg_source:\n",
    "                if pulse_ppg != move_frequence:\n",
    "                    freqs.append(pulse_ppg)\n",
    "                    snrs.append(snr_ppg)\n",
    "                    break\n",
    "                    \n",
    "        eval_frq, most_common_pulse_percent,max_snr= select_most_common_with_max_coefficient(freqs,snrs)            \n",
    "        #combine found frequency with snr\n",
    "        #pulse_snr_pairs = list(zip(freqs,snrs))\n",
    "        #prioritize when a value occure the most of time\n",
    "        #most_common_pulse, count = Counter(freqs).most_common(1)[0]\n",
    "        #find the occurence to get max snrs\n",
    "        #common_pulse_snr_pairs = [pulse_snr_pair for pulse_snr_pair in pulse_snr_pairs if pulse_snr_pair[0] == most_common_pulse]\n",
    "        #max_snr = max(common_pulse_snr_pairs, key=lambda x: x[1])[1]\n",
    "        #most_common_pulse_percent = count/len(freqs)\n",
    "        #rules to be affined \n",
    "        #from the multiple ppg signal we select the most common signal\n",
    "        eval_bpm = eval_frq*60\n",
    "        \n",
    "        #Rules to compute the cofidence\n",
    "        #1. **Compute coeff1:**\n",
    "        #   - Calculate how common the signal is among all signals, expressed as a percentage.\n",
    "        #   - coeff1 represents this percentage.\n",
    "        #  \n",
    "        #2. **Compute coeff2:**\n",
    "        #   - Identify the signal with the highest Signal-to-Noise Ratio (SNR).\n",
    "        #   - Apply the following rule for coeff2:\n",
    "        #      - If SNR is greater than the threshold (15), then coeff2 = 0.75.\n",
    "        #      - If SNR is less than or equal to the threshold, then coeff2 = 0.40.\n",
    "        #\n",
    "        #3. **Calculate confidence:**\n",
    "        #   - Multiply coeff1 by coeff2 to obtain the confidence value.\n",
    "        confidence = 0\n",
    "        \n",
    "        if max_snr > snr_threshold: \n",
    "            confidence = 0.75\n",
    "        else:\n",
    "            confidence = 0.40\n",
    "\n",
    "        confidence = confidence * most_common_pulse_percent\n",
    "    \n",
    "    return eval_bpm, confidence\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    # filtering band to retrieve pulsation\n",
    "    pass_band = (40/60,240/60)\n",
    "    # sample frequencies\n",
    "    fs=125\n",
    "    threshold = 15\n",
    "    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    _,ppg1, ppg2, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    \n",
    "    #constant from study: TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise\n",
    "    window = 8\n",
    "    step = 2\n",
    "    \n",
    "    acc = compute_acceleration_resultant(accx,accy,accz)\n",
    "    freqencies_acc = extract_frequencies_for_highest_amplitudes(acc,\n",
    "                                                                fs,\n",
    "                                                                window,\n",
    "                                                                step,\n",
    "                                                                pass_band=pass_band,\n",
    "                                                                display=False)\n",
    "    \n",
    "    frequencies_ppg_1 = extract_frequencies_for_highest_amplitudes(ppg1,\n",
    "                                                                   fs,\n",
    "                                                                   window,\n",
    "                                                                   step,\n",
    "                                                                   pass_band=pass_band,\n",
    "                                                                   display=False)\n",
    "    \n",
    "    frequencies_ppg_2 = extract_frequencies_for_highest_amplitudes(ppg2,\n",
    "                                                                   fs,\n",
    "                                                                   window,\n",
    "                                                                   step,\n",
    "                                                                   pass_band=pass_band,\n",
    "                                                                   display=False)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    pulsations_segments_ecg,pulsation_mean_ecg,pulsation_std_ecg = extract_heart_pulsations_from_ecg(ecg,\n",
    "                                                                                                     fs,\n",
    "                                                                                                     window,\n",
    "                                                                                                     step,\n",
    "                                                                                                     pass_band=pass_band,\n",
    "                                                                                                     display=True)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    #ppg_top_frq=extract_ntop_freq(ppg,fs,n=6,display=False)\n",
    "    #acc_top_frq=extract_ntop_freq(acc,fs,n=6,display=False)\n",
    "    ref_bpms = LoadTroikaDataReferenceFile(ref_fl)\n",
    "    display = False\n",
    "      \n",
    "    eval_bpms = []\n",
    "    confidences = []\n",
    "    for i in range(len(frequencies_ppg_1)):\n",
    "       \n",
    "       #print(f'batch {i*window} s - {(i+1)*window} s')\n",
    "       \n",
    "       #eval_bpm, confidence= evaluate_bpm([frequencies_ppg_1[i],frequencies_ppg_2[i]],freqencies_acc[i],snr_threshold = 15)\n",
    "       eval_bpm, confidence= evaluate_bpm([frequencies_ppg_2[i]],freqencies_acc[i],snr_threshold = 15)\n",
    "\n",
    "       eval_bpms.append(eval_bpm)\n",
    "       confidences.append(confidence)\n",
    "    \n",
    "    l_eval = len(eval_bpms)\n",
    "    l_ref = len(ref_bpms)\n",
    "    delta = l_eval - l_ref\n",
    "    errors = None\n",
    "    \n",
    "    reliabilities = np.array(confidences)\n",
    "    if delta < 0:\n",
    "        delta = -delta\n",
    "        errors = np.abs( np.array(eval_bpms) -  np.array(ref_bpms)[:-delta])\n",
    "        ## add missing (-1) to error\n",
    "        errors = np.concatenate((errors, np.full(delta, -1) ))\n",
    "    elif delta > 0:\n",
    "        errors = np.abs( np.array(eval_bpms[:-delta]) -  np.array(ref_bpms))\n",
    "        ## add extra (-2) to error\n",
    "        errors = np.concatenate((errors, np.full(delta, -2) ))\n",
    "    else:\n",
    "        errors = np.abs( np.array(eval_bpms) -  np.array(ref_bpms))\n",
    "\n",
    "    #print(f'{len(reliabilities)} = {len(errors)}')\n",
    "        \n",
    "    if display:\n",
    "        #sns.lineplot(y='Eval',  ci=95, data=df,label='eval')\n",
    "        # ci=None, marker='o'\n",
    "        #sns.lineplot(data= df, ci=95, marker='o')\n",
    "        #plt.show()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.plot(eval_bpms)\n",
    "        plt.plot(ref_bpms)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    return errors, reliabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "grader_mode": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
